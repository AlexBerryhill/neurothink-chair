{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22147e42",
   "metadata": {},
   "source": [
    "# Direction Thought Detection\n",
    "\n",
    "In this notebook we will train a model to determine whether a person is thinking `left`, `right`, or `none`.\n",
    "\n",
    "## Running a Survey\n",
    "\n",
    "First we can import our library and create a survey, so we can train a model on the resulting data. We'll ask the participant to first get into a comfortable position, think of left, think of right, think of none, etc. 3x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Reload external source files when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from datetime import timedelta, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from recorder import Muse2EEGRecorder\n",
    "from survey import Survey\n",
    "\n",
    "left_step = (timedelta(seconds=30), \"left\", \"Think about going left.\", True)\n",
    "right_step = (timedelta(seconds=30), \"right\", \"Think about going right.\", True)\n",
    "none_step = (timedelta(seconds=30), \"right\", \"Just breathe.\", True)\n",
    "direction_schedule = [\n",
    "    (timedelta(seconds=30), \"intro\", \"Just breathe normally, gently relax any tension, and get into a comfortable position.\", False),\n",
    "    left_step,\n",
    "    right_step,\n",
    "    none_step,\n",
    "    left_step,\n",
    "    right_step,\n",
    "    none_step,\n",
    "    left_step,\n",
    "    right_step,\n",
    "    none_step\n",
    "]\n",
    "\n",
    "test_schedule = [\n",
    "    (timedelta(seconds=5), \"intro\", \"Just breathe normally, gently relax any tension, get in a comfortable position.\", True)\n",
    "]\n",
    "\n",
    "muse2_recorder = Muse2EEGRecorder()\n",
    "direction_survey = Survey(muse2_recorder, \"Left-Right-Thoughts\", \"Thinking 'left' for 30s, then 'right', then 'none' - repeat 3x.\", direction_schedule)\n",
    "direction_survey.record(\"Jared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc3874",
   "metadata": {},
   "source": [
    "## Preparing Data for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4dd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from eeg_preprocessing import preprocess_eeg_channel\n",
    "from eegdata import EEGSurveyDataset, ChunkedDataset, MultiDataset\n",
    "\n",
    "def transform_normalize(data):\n",
    "    for ch in range(data.shape[1]):\n",
    "        data[:, ch] = preprocess_eeg_channel(data[:, ch])\n",
    "        stddev = data[:, ch].std()\n",
    "        if stddev != 0:\n",
    "            data[:, ch] = (data[:, ch] - data[:, ch].mean()) / stddev\n",
    "    return data\n",
    "\n",
    "batch_size = 35\n",
    "\n",
    "# Create PyTorch Datasets\n",
    "ds1 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 15:35:13.033803\", 7665, transform=transform_normalize)\n",
    "ds2 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 15:42:18.386982\", 7665, transform=transform_normalize)\n",
    "ds3 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 16:30:50.691073\", 7665, transform=transform_normalize)\n",
    "ds4 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 16:35:02.095245\", 7665, transform=transform_normalize)\n",
    "ds5 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 16:50:59.722742\", 7665, transform=transform_normalize)\n",
    "ds6 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 16:55:04.568128\", 7665, transform=transform_normalize)\n",
    "ds7 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 17:56:48.686557\", 7665, transform=transform_normalize)\n",
    "ds8 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 18:00:38.062883\", 7665, transform=transform_normalize)\n",
    "ds9 = EEGSurveyDataset(\"../data/muse2-recordings/surveys/Eyes open-closed Jared 2021-06-27 18:04:25.933181\", 7665, transform=transform_normalize)\n",
    "ds1, ds2, ds3, ds4, ds5, ds6, ds7, ds8, ds9 = ChunkedDataset(ds1, batch_size), ChunkedDataset(ds2, batch_size), ChunkedDataset(ds3, batch_size), ChunkedDataset(ds4, batch_size), ChunkedDataset(ds5, batch_size), ChunkedDataset(ds6, batch_size), ChunkedDataset(ds7, batch_size), ChunkedDataset(ds8, batch_size), ChunkedDataset(ds9, batch_size)\n",
    "train_dataset = MultiDataset([ds1, ds2, ds3, ds4, ds5, ds9, ds8])\n",
    "test_dataset = MultiDataset([ds6, ds7])\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb74042",
   "metadata": {},
   "source": [
    "## PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_channels = 4\n",
    "n_outputs = 2\n",
    "\n",
    "# Create model\n",
    "net = nn.Sequential(\n",
    "    # Pass input to a 1D convolutional layer with a kernel size of 3, apply to activation function.\n",
    "    nn.Conv1d(n_channels, 32, 3),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # Pass previous layer output to a 1D convolutional layer with a kernel size of 2, apply to activation function,\n",
    "    # and get the max value from each kernel.\n",
    "    nn.Conv1d(32, 32, 2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel_size=2),\n",
    "\n",
    "    # Pass previous layer output to a 1D convolutional layer with a kernel size of 2, apply to activation function,\n",
    "    # and get the max value from each kernel. (same as previous layer)\n",
    "    nn.Conv1d(32, 32, 2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel_size=2),\n",
    "\n",
    "    # Flatten the convolutions. Input shape: (a, b, c), Output shape: (a, b*c)\n",
    "    nn.Flatten(),\n",
    "    \n",
    "    #nn.Dropout(0.5),\n",
    "    # ?\n",
    "    # XXX: The first number needs to be updated each time the input shapes change. We could instead\n",
    "    #      Create a class-based Module, and do a single pass through the conv portion of the network\n",
    "    #      in order to determine the actual size.\n",
    "    #      (This technique is shown in https://www.youtube.com/watch?v=1gQR24B3ISE&list=PLQVvvaa0QuDdeMyHEYc0gxFpYwHY2Qfdh&index=7).\n",
    "    #      For now, we can update this value as needed by commenting out all layers after Flatten(), then running the code\n",
    "    #      below and inspecting the output shape. The x[1] value should be the first arg in the following line.\n",
    "    nn.Linear(1696, 512),  # ~= nn.LazyLinear(512)\n",
    "\n",
    "    # Flatten the linear layer into the required number of outputs\n",
    "    nn.Linear(512, n_outputs),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "for i, data in enumerate(train_dataloader, 0):\n",
    "    features, labels = data\n",
    "    print(\"Model input shape:\", features.shape)\n",
    "    out = net(features.float())\n",
    "    print(\"Model output shape:\", out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc2cbe",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train for n epochs\n",
    "n = 80\n",
    "test_while_training = True\n",
    "\n",
    "loss_history = []\n",
    "eval_history = []\n",
    "count = 0\n",
    "net.train()\n",
    "for epoch in tqdm(range(n)):\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        features, labels = data\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        #net.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        predictions = net(features.float())\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, labels.long())\n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    # Evaluate the model against the test dataset\n",
    "    if test_while_training:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_dataloader, 0):\n",
    "                features, labels = data\n",
    "                out = net(features.float())\n",
    "                preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "        eval_history.append(correct / total)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.title(\"Training session\")\n",
    "print(\"Passes per epoch:\", count / n)\n",
    "print(\"Final Loss:\", loss_history[-1])\n",
    "plt.plot(np.linspace(0, 1, len(loss_history)), loss_history, label=\"Loss\")\n",
    "if test_while_training:\n",
    "    print(f\"Final Accuracy: {int(100*eval_history[-1])}%\")\n",
    "    plt.plot(np.linspace(0, 1, len(eval_history)), eval_history, label=\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    Model input shape: torch.Size([35, 4, 219])\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        features, labels = data\n",
    "        out = net(features.float())\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "model_accuracy = int(correct / total * 100)\n",
    "print(\"Correct:\", correct, \"/\", total, \"-\", f\"{model_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c39b4",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ac096",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(datetime.now())\n",
    "torch.save(net.state_dict(), f\"../models/{timestamp}-Muse_EEG_eyes_open-{model_accuracy}percent.pt\")\n",
    "with open(f\"../models/{timestamp}-Muse_EEG_eyes_open-{model_accuracy}percent.model\", \"w\") as f:\n",
    "    f.write(str(net))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
